{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgOe3NtB-q2X"
      },
      "source": [
        "# MLB Project 4 Main - Fine-Tuning a Language Model\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "Welcome to the Fine-Tuning Project! In this project, you'll learn how to **fine-tune a pre-trained language model** for sentiment analysis on product reviews.\n",
        "\n",
        "### What is Fine-Tuning?\n",
        "Fine-tuning is the process of taking a pre-trained model and adapting it to a specific task by training it on task-specific data. This allows you to leverage the general language understanding the model has already learned while specializing it for your particular use case.\n",
        "\n",
        "### What You'll Learn\n",
        "- How to load and preprocess a dataset for fine-tuning\n",
        "- How to prepare a pre-trained model for a classification task\n",
        "- How to set up training arguments and optimize hyperparameters\n",
        "- How to train and evaluate a fine-tuned model\n",
        "- How to make predictions with your trained model\n",
        "\n",
        "### Project Structure\n",
        "1. Setup and imports\n",
        "2. Data loading and exploration\n",
        "3. Data preprocessing and tokenization\n",
        "4. Model preparation\n",
        "5. Training configuration\n",
        "6. Model training\n",
        "7. Evaluation and inference\n",
        "\n",
        "### Dataset: Amazon Product Reviews\n",
        "We'll use a subset of Amazon product reviews with ratings from 1-5 stars. Your task is to predict the sentiment (positive/negative/neutral) based on the review text.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkvDxZKt-q2Y"
      },
      "source": [
        "## Step 1: Setup and Imports\n",
        "\n",
        "First, let's install the required libraries and import them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_raVXQ2-q2Z"
      },
      "outputs": [],
      "source": [
        "# Install required packages (run this cell first!)\n",
        "!pip install transformers datasets torch scikit-learn accelerate evaluate -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9Sk_S1i-q2Z"
      },
      "outputs": [],
      "source": [
        "# Import all necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import torch\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import evaluate\n",
        "\n",
        "# Suppress unnecessary warnings for cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGKilY6Y-q2Z"
      },
      "source": [
        "## Step 2: Configuration\n",
        "\n",
        "Let's set up our model names and training configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaYaJfws-q2Z"
      },
      "outputs": [],
      "source": [
        "# Configuration settings\n",
        "MODEL_NAME = \"distilbert-base-uncased\"  # A lighter, faster version of BERT\n",
        "MAX_LENGTH = 128  # Maximum sequence length for tokenization\n",
        "BATCH_SIZE = 16  # Number of samples per training batch\n",
        "NUM_EPOCHS = 3  # Number of training epochs\n",
        "LEARNING_RATE = 2e-5  # Learning rate for the optimizer\n",
        "\n",
        "# Label mapping\n",
        "LABEL_MAPPING = {\n",
        "    0: \"negative\",  # 1-2 star reviews\n",
        "    1: \"neutral\",   # 3 star reviews\n",
        "    2: \"positive\"   # 4-5 star reviews\n",
        "}\n",
        "\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print(f\"Max Length: {MAX_LENGTH}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqaXXQ84-q2a"
      },
      "source": [
        "## Step 3: Load and Explore the Dataset\n",
        "\n",
        "We'll use the Amazon Polarity dataset which contains product reviews. We'll convert the ratings into sentiment labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYncA5dj-q2a"
      },
      "source": [
        "### 3.1: Load the Dataset\n",
        "\n",
        "**TODO**: Load the dataset and take a smaller subset for faster training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGjPWOwp-q2a"
      },
      "outputs": [],
      "source": [
        "print(\"Loading dataset...\")\n",
        "\n",
        "# TODO: Load the amazon_polarity dataset\n",
        "dataset = None  # Replace None with your code\n",
        "\n",
        "# We'll take a smaller subset for faster training (5000 samples)\n",
        "# TODO: Select the first 5000 samples from the dataset\n",
        "dataset = None  # Replace None with your code\n",
        "\n",
        "print(f\"Dataset loaded with {len(dataset)} samples\")\n",
        "print(f\"\\nDataset structure: {dataset}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmjkXXTS-q2a"
      },
      "source": [
        "### 3.2: Explore the Data\n",
        "\n",
        "Let's examine some sample reviews to understand the data better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTolhy7L-q2a"
      },
      "outputs": [],
      "source": [
        "# TODO: Display the first 3 examples from the dataset\n",
        "print(\"Sample reviews:\\n\")\n",
        "for i in range(3):\n",
        "    sample = None  # Replace None with code to get sample i\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(f\"Title: {sample['title']}\")\n",
        "    print(f\"Content: {sample['content'][:200]}...\")  # Show first 200 chars\n",
        "    print(f\"Label: {sample['label']} ({LABEL_MAPPING[sample['label']]})\")\n",
        "    print(\"-\" * 80)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h2DF0Nc-q2a"
      },
      "source": [
        "### 3.3: Prepare Labels\n",
        "\n",
        "The amazon_polarity dataset has binary labels (0=negative, 1=positive). For this project, we'll work with these as-is, but you could extend this to include neutral sentiment.\n",
        "\n",
        "**TODO**: Create a function to combine title and content into a single text field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUJIbgLu-q2a"
      },
      "outputs": [],
      "source": [
        "def prepare_text(example):\n",
        "    \"\"\"\n",
        "    Combine title and content into a single text field.\n",
        "\n",
        "    Args:\n",
        "        example: A single example from the dataset\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with 'text' and 'label' fields\n",
        "    \"\"\"\n",
        "    # TODO: Combine title and content with a separator\n",
        "    text = None  # Replace None with your code\n",
        "\n",
        "    return {\n",
        "        'text': text,\n",
        "        'label': example['label']\n",
        "    }\n",
        "\n",
        "# TODO: Apply the prepare_text function to the entire dataset\n",
        "dataset = None  # Replace None with your code\n",
        "\n",
        "print(\"Text preparation complete!\")\n",
        "print(f\"\\nUpdated dataset structure: {dataset}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhj0MEvD-q2a"
      },
      "source": [
        "### 3.4: Split the Dataset\n",
        "\n",
        "**TODO**: Split the dataset into training, validation, and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fOaWhDe-q2a"
      },
      "outputs": [],
      "source": [
        "# TODO: Split the dataset into train (70%), validation (15%), and test (15%)\n",
        "\n",
        "# First split: 70% train, 30% temp\n",
        "train_test = None  # Replace None with your code\n",
        "\n",
        "# Second split: Split the temp set into 50% validation, 50% test\n",
        "val_test = None  # Replace None with your code\n",
        "\n",
        "# Create the final dataset dictionary\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': train_test['train'],\n",
        "    'validation': val_test['train'],\n",
        "    'test': val_test['test']\n",
        "})\n",
        "\n",
        "print(\"Dataset split complete!\")\n",
        "print(f\"\\nDataset splits:\")\n",
        "print(f\"   Training: {len(dataset_dict['train'])} samples\")\n",
        "print(f\"   Validation: {len(dataset_dict['validation'])} samples\")\n",
        "print(f\"   Test: {len(dataset_dict['test'])} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP9iR8zy-q2b"
      },
      "source": [
        "## Step 4: Tokenization\n",
        "\n",
        "Tokenization converts text into numerical tokens that the model can understand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNKZ6xrV-q2b"
      },
      "source": [
        "### 4.1: Load the Tokenizer\n",
        "\n",
        "**TODO**: Load the tokenizer for our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNgYrC6o-q2b"
      },
      "outputs": [],
      "source": [
        "print(\"Loading tokenizer...\")\n",
        "\n",
        "# TODO: Load the tokenizer using AutoTokenizer\n",
        "tokenizer = None  # Replace None with your code\n",
        "\n",
        "print(f\"Tokenizer loaded: {tokenizer.__class__.__name__}\")\n",
        "print(f\"Vocabulary size: {len(tokenizer)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTyv3OzC-q2b"
      },
      "source": [
        "### 4.2: Create Tokenization Function\n",
        "\n",
        "**TODO**: Create a function to tokenize the text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0D4WRVF-q2b"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(examples):\n",
        "    \"\"\"\n",
        "    Tokenize the text in the examples.\n",
        "\n",
        "    Args:\n",
        "        examples: Batch of examples from the dataset\n",
        "\n",
        "    Returns:\n",
        "        Tokenized examples\n",
        "    \"\"\"\n",
        "    # TODO: Tokenize the text with padding and truncation\n",
        "    return None  # Replace None with your code\n",
        "\n",
        "# TODO: Apply tokenization to all splits\n",
        "print(\"Tokenizing datasets...\")\n",
        "tokenized_datasets = None  # Replace None with your code\n",
        "\n",
        "print(\"Tokenization complete!\")\n",
        "print(f\"\\nTokenized dataset structure: {tokenized_datasets}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD1tWlcV-q2b"
      },
      "source": [
        "### 4.3: Verify Tokenization\n",
        "\n",
        "Let's check that tokenization worked correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-bEKqQo-q2b"
      },
      "outputs": [],
      "source": [
        "# Examine a tokenized example\n",
        "print(\"Sample tokenized example:\\n\")\n",
        "sample = tokenized_datasets['train'][0]\n",
        "print(f\"Input IDs shape: {len(sample['input_ids'])}\")\n",
        "print(f\"Input IDs (first 20): {sample['input_ids'][:20]}\")\n",
        "print(f\"\\nDecoded text: {tokenizer.decode(sample['input_ids'][:50])}...\")\n",
        "print(f\"Label: {sample['label']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xAzN3gD-q2b"
      },
      "source": [
        "## Step 5: Prepare the Model\n",
        "\n",
        "Now we'll load the pre-trained model and prepare it for our classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLJygPdj-q2b"
      },
      "source": [
        "### 5.1: Load the Model\n",
        "\n",
        "**TODO**: Load the pre-trained model for sequence classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGpJy7aq-q2b"
      },
      "outputs": [],
      "source": [
        "print(\"Loading pre-trained model...\")\n",
        "\n",
        "# TODO: Load the model for sequence classification\n",
        "model = None  # Replace None with your code\n",
        "\n",
        "print(f\"Model loaded: {model.__class__.__name__}\")\n",
        "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT8q7JQx-q2b"
      },
      "source": [
        "### 5.2: Create Data Collator\n",
        "\n",
        "A data collator handles batching and padding during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abrFH5Kh-q2b"
      },
      "outputs": [],
      "source": [
        "# TODO: Create a data collator with padding\n",
        "data_collator = None  # Replace None with your code\n",
        "\n",
        "print(\"Data collator created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqU8gNTG-q2c"
      },
      "source": [
        "## Step 6: Define Evaluation Metrics\n",
        "\n",
        "We need to define how to evaluate our model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9K7y7z1-q2c"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Compute evaluation metrics for the model.\n",
        "\n",
        "    Args:\n",
        "        eval_pred: Tuple of (predictions, labels)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of metric values\n",
        "    \"\"\"\n",
        "    # TODO: Extract predictions and labels\n",
        "    predictions, labels = None, None  # Replace None with your code\n",
        "\n",
        "    # TODO: Get predicted class by taking argmax\n",
        "    predictions = None  # Replace None with your code\n",
        "\n",
        "    # TODO: Calculate accuracy\n",
        "    accuracy = None  # Replace None with your code\n",
        "\n",
        "    # TODO: Calculate precision, recall, and F1\n",
        "    precision, recall, f1, _ = None, None, None, None  # Replace with your code\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "print(\"Metrics function defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqrEFfF_-q2c"
      },
      "source": [
        "## Step 7: Set Up Training Arguments\n",
        "\n",
        "Training arguments control how the model is trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQ8jbSBL-q2c"
      },
      "outputs": [],
      "source": [
        "# TODO: Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",              # Output directory for checkpoints\n",
        "    num_train_epochs=None,               # TODO\n",
        "    per_device_train_batch_size=None,    # TODO\n",
        "    per_device_eval_batch_size=None,     # TODO\n",
        "    learning_rate=None,                  # TODO\n",
        "    weight_decay=0.01,                   # Regularization\n",
        "    eval_strategy=\"epoch\",               # Evaluate after each epoch\n",
        "    save_strategy=\"epoch\",               # Save checkpoint after each epoch\n",
        "    load_best_model_at_end=True,         # Load best model at the end\n",
        "    metric_for_best_model=\"accuracy\",    # Use accuracy to determine best model\n",
        "    logging_dir=\"./logs\",                # TensorBoard logs\n",
        "    logging_steps=50,                    # Log every 50 steps\n",
        "    warmup_steps=100,                    # Warmup steps for learning rate\n",
        "    seed=42,                             # Random seed\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "print(\"Training arguments configured!\")\n",
        "print(f\"\\nTraining configuration:\")\n",
        "print(f\"Epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"Batch size: {training_args.per_device_train_batch_size}\")\n",
        "print(f\"Learning rate: {training_args.learning_rate}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmCA28RY-q2c"
      },
      "source": [
        "## Step 8: Create the Trainer\n",
        "\n",
        "The Trainer handles the training loop, evaluation, and logging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDljAFhM-q2c"
      },
      "outputs": [],
      "source": [
        "# TODO: Create a Trainer instance\n",
        "trainer = None  # Replace None with your code\n",
        "\n",
        "print(\"Trainer created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xejdr6UO-q2c"
      },
      "source": [
        "## Step 9: Train the Model\n",
        "\n",
        "Now we're ready to train! This will take several minutes.\n",
        "\n",
        "**TODO**: Start the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QFqibL8-q2c"
      },
      "outputs": [],
      "source": [
        "print(\"Starting training...\\n\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# TODO: Train the model\n",
        "train_result = None  # Replace None with your code\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Training complete!\")\n",
        "print(f\"\\nTraining metrics:\")\n",
        "print(f\"Final loss: {train_result.training_loss:.4f}\")\n",
        "print(f\"Training time: {train_result.metrics['train_runtime']:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31W4oVsh-q2c"
      },
      "source": [
        "## Step 10: Evaluate the Model\n",
        "\n",
        "Let's evaluate our fine-tuned model on the validation and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btIkxQPv-q2c"
      },
      "source": [
        "### 10.1: Validation Set Evaluation\n",
        "\n",
        "**TODO**: Evaluate on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UetrdVFd-q2c"
      },
      "outputs": [],
      "source": [
        "print(\"Evaluating on validation set...\\n\")\n",
        "\n",
        "# TODO: Evaluate the model on validation set\n",
        "val_results = None  # Replace None with your code\n",
        "\n",
        "print(\"Validation results:\")\n",
        "for metric, value in val_results.items():\n",
        "    if metric.startswith('eval_'):\n",
        "        print(f\"   {metric[5:]}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7vhgGcW-q2c"
      },
      "source": [
        "### 10.2: Test Set Evaluation\n",
        "\n",
        "**TODO**: Evaluate on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7MDFP0I-q2c"
      },
      "outputs": [],
      "source": [
        "print(\"Evaluating on test set...\\n\")\n",
        "\n",
        "# TODO: Evaluate the model on test set\n",
        "test_results = None  # Replace None with your code\n",
        "\n",
        "print(\"Test results:\")\n",
        "for metric, value in test_results.items():\n",
        "    if metric.startswith('eval_'):\n",
        "        print(f\"   {metric[5:]}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI5cTcfL-q2h"
      },
      "source": [
        "## Step 11: Make Predictions\n",
        "\n",
        "Now let's use our fine-tuned model to make predictions on new text!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OllyMZEt-q2h"
      },
      "source": [
        "### 11.1: Create Prediction Function\n",
        "\n",
        "**TODO**: Create a function to predict sentiment for new reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuqPS3QT-q2h"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(text: str, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Predict the sentiment of a text review.\n",
        "\n",
        "    Args:\n",
        "        text: Review text to classify\n",
        "        model: Fine-tuned model\n",
        "        tokenizer: Tokenizer\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (predicted_label, confidence_score)\n",
        "    \"\"\"\n",
        "    # TODO: Tokenize the input text\n",
        "    inputs = None  # Replace None with your code\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # TODO: Get model predictions (no gradient calculation needed)\n",
        "    with torch.no_grad():\n",
        "        outputs = None  # Replace None with your code\n",
        "\n",
        "    # TODO: Get the predicted class\n",
        "    predicted_class = None  # Replace None with your code\n",
        "\n",
        "    # TODO: Calculate confidence score using softmax\n",
        "    probabilities = torch.softmax(outputs.logits, dim=1)\n",
        "    confidence = None  # Replace None with your code\n",
        "\n",
        "    # Map to label name\n",
        "    label_name = LABEL_MAPPING[predicted_class.item()]\n",
        "\n",
        "    return label_name, confidence.item()\n",
        "\n",
        "print(\"Prediction function defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPUjrDrQ-q2h"
      },
      "source": [
        "### 11.2: Test with Sample Reviews\n",
        "\n",
        "Let's test our model with some example reviews!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQKhMZ3U-q2h"
      },
      "outputs": [],
      "source": [
        "# Sample reviews to test\n",
        "test_reviews = [\n",
        "    \"This product is amazing! Best purchase I've ever made. Highly recommend!\",\n",
        "    \"Terrible quality. Broke after one day. Complete waste of money.\",\n",
        "    \"This is absolutely the worst product I have ever purchased. Save your money!\",\n",
        "    \"Great value for the price. Works exactly as described.\",\n",
        "    \"Not bad, but not great either. It's okay for the price.\"\n",
        "]\n",
        "\n",
        "print(\"Making predictions on sample reviews:\\n\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for i, review in enumerate(test_reviews, 1):\n",
        "    # TODO: Get prediction for the review\n",
        "    sentiment, confidence = None, None  # Replace with your code\n",
        "\n",
        "    print(f\"\\nReview {i}: {review}\")\n",
        "    print(f\"Predicted Sentiment: {sentiment.upper()}\")\n",
        "    print(f\"Confidence: {confidence:.2%}\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3LKxPBo-q2h"
      },
      "source": [
        "### 11.3: Interactive Prediction\n",
        "\n",
        "Try it yourself! Enter your own reviews to classify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYfWnqZt-q2h"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Interactive Sentiment Classifier\")\n",
        "print(\"Enter product reviews to classify their sentiment.\")\n",
        "print(\"Type 'exit' or 'quit' to stop.\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "while True:\n",
        "    # Get user input\n",
        "    review = input(\"\\nüìù Enter a review: \")\n",
        "\n",
        "    # Check if user wants to exit\n",
        "    if review.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"\\nüëã Thank you for using the sentiment classifier!\")\n",
        "        break\n",
        "\n",
        "    # Skip empty input\n",
        "    if not review.strip():\n",
        "        continue\n",
        "\n",
        "    # TODO: Get prediction\n",
        "    sentiment, confidence = None, None  # Replace with your code\n",
        "\n",
        "    print(f\"\\n‚ú® Prediction: {sentiment.upper()}\")\n",
        "    print(f\"üìä Confidence: {confidence:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQxVYhkF-q2i"
      },
      "source": [
        "## üéì Congratulations!\n",
        "\n",
        "You've successfully fine-tuned a language model for sentiment analysis! Here's what you accomplished:\n",
        "\n",
        "1. ‚úÖ Loaded and preprocessed the Amazon product reviews dataset\n",
        "2. ‚úÖ Tokenized text data for model input\n",
        "3. ‚úÖ Configured and loaded a pre-trained DistilBERT model\n",
        "4. ‚úÖ Set up training arguments and evaluation metrics\n",
        "5. ‚úÖ Fine-tuned the model on sentiment classification\n",
        "6. ‚úÖ Evaluated model performance on validation and test sets\n",
        "7. ‚úÖ Created a prediction function for new reviews\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "Want to improve your model? Try:\n",
        "- Training for more epochs\n",
        "- Experimenting with different learning rates\n",
        "- Using a larger model (e.g., BERT-base instead of DistilBERT)\n",
        "- Adding more training data\n",
        "- Implementing data augmentation techniques\n",
        "- Trying different optimizers or schedulers\n",
        "- Fine-tuning on a different task (e.g., multi-class classification)\n",
        "- Adding attention visualization to understand model decisions\n",
        "\n",
        "### Additional Resources\n",
        "\n",
        "- [Hugging Face Transformers Documentation](https://huggingface.co/docs/transformers/)\n",
        "- [Fine-tuning Guide](https://huggingface.co/docs/transformers/training)\n",
        "- [DistilBERT Paper](https://arxiv.org/abs/1910.01108)\n",
        "- [Transfer Learning in NLP](https://ruder.io/transfer-learning/)\n",
        "\n",
        "### Challenge Tasks\n",
        "\n",
        "1. **Hyperparameter Tuning**: Experiment with different batch sizes, learning rates, and epochs to improve performance\n",
        "2. **Model Comparison**: Try fine-tuning different models (BERT, RoBERTa, ALBERT) and compare results\n",
        "3. **Error Analysis**: Analyze misclassified examples to understand model limitations\n",
        "4. **Deployment**: Create a simple web app using Gradio or Streamlit to deploy your model\n",
        "\n",
        "Great work! üéâ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}